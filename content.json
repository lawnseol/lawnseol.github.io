{"pages":[],"posts":[{"title":"Artificial Intelligence","text":"인공지능 연구의 목적 인공지능을 다루는 과학자의 대부분은 인공지능을 통해서 인간의 지능이나 뇌의 기능을 해명하고 싶다. 인공지능을 통해서 인간의 지능이나 기능을 구현하고 싶다. 인공지능 개념적 목표 인간이 가진 지능을 만들고 싶다 인간과 동일한 구조를 가지고 인간처럼 동작하는, 행동 뿐만 아니라 내부 구조까지 인간과 같은 것을 만들고 싶다. 인간의 지능으로 실현할 수 있는 기능을 만들고 싶다 구조가 완전하게 인간과 같은지는 제쳐두고 표면적인 행동이나 기능을 구현하는 방법만을 생각하는 것으로 인간과 완벽하게 같은 지능을 만들기 어렵기 때문에 현재 인공지능을 연구하는 목표이다. 인간의 지능으로도 실현하기 어려운 기능을 만들고 싶다 인간이 가진 지능에만 국한되지 않고 그보다도 더 굉장한 지능을 목표로 한다. 인공지능에서의 지식 인공지능의 역사는 인공지능을 똑똑하게 하기 위해 지식을 가르치는 구조를 해석하고 정의하면서 발전했다고 볼 수 있다. 인공지능의 역사를 이해하기 위해서 우선 지식이란 무엇인지 알아보기로 한다. 사전적 정의 어떤 대상에 대하여 배우거나 실천을 통하여 알게 된 명확한 인식이나 이해. 알고 있는 내용이나 사물. 철학 인식에 의하여 얻어진 성과. 사물에 대한 단편적인 사실적ㆍ경험적 인식을 말하며, 객관적 타당성을 요구할 수 있는 판단의 체계를 이른다. 사전적 의미로 보자면 지식이란 곧 어떤 사람이 ‘알고 있는(인식)’, 또는 ‘(이해)하고 있는’ 것을 말한다. 지식 습득 조건 어떤 인물 A가 어떠한 사항 P를 알고 있다를 정의하려면 다음 세가지 조건을 만족해야 한다. A는 P를 신뢰하고 있다. P는 사실이다. A는 P를 신뢰할 만한 이유가 있다. 만약 A가 '지금은 10시다’라는 사항을 알고 있다고 가정하고, 조건 1만 만족했다면 지금 상황은 A가 '지금은 10시다’라고 믿고 있을 뿐입니다. 그저 그 사람이 그렇게 생각하고 있을 뿐인데 그 사람이 '알고 있다’고 하기엔 무리가 있다. 조건 2를 더한다고 하면 A가 '지금 10시다’라고 믿고 있고, 실제로도 시간이 10시가 된다. 이 경우는 사실 A가 아무 근거없이 그저 '지금은 10시다’라고 생각했을 뿐인데 우연히 현재 10시였을 가능성도 있기 때문이다. 조건 3을 더하면 A가 눈앞의 시계를 보고 있고 시계가 10시를 가리키고 있는 경우 A가 '지금 10시다’라는 사실을 알고 있다고 할 수 있다. 하지만 여기서 시계가 고장났다면, 오전10시인지 오후 10시인지 등 다양한 부분에 대해 지식의 종류 지식표현방법 역사 제1차 부흥기 인공지능은 1940년대부터 연구하기 시작했지만 인공지능(AI, Artificial Intelligence)라는 표현은 1956년 '다트머스 회의’가 최초였다. 다트머스 회의는 인공지능에 관한 연구 발표의 장으로 당시 컴퓨터상에서 기호 처리를 통해 퍼즐 등을 고속으로 풀 수 있다는 것이 판명되었고, 연구가 진행됨에 따라 모든 사람이 컴퓨터의 가능성을 높이 사고 있는 시대였다. 이때 주된 개념은 '지능이란 곧 기호 처리’였다. 대화시스템에 대한 연구도 시작되었는데 ELIZA(일라이자)라는 대화시스템은 상담 치료사 역할을 하면서 텍스트 채팅을 통해 인간과 대화를 하는 방식이었다. ELIZA는 자신이 먼저 능동적으로 무언가를 말하지는 않고 사용자의 이야기를 수동적으로 받아들일 뿐인 시스템으로 이런 대화를 반복하면서 사용자가 점점 '나에 대해 이해해준다’는 느낌을 받게 구성되어 있었다. SHRDLU라는 대화시스템은 쌓기 블록이 표시된 블록을 옮기는 시스템으로 블록을 움직이기 위한 명령이나 순서를 처리할 수 있도록 구성되었다. 인공지능을 퍼즐과 같은 문제(Toy problem)는 풀 수 있어도 사회에 실제로 도움이 될 법한 문제에는 손 쓸 방법이 없었기 때문에 제1차 부흥기는 금방 끝나고 만다. 이러한 문제들을 '프레임 문제’라고 불렀다. 프레임 문제는 인공지능이 문제를 해결할 때 고려해야 할 범위(프레임)를 제대로 설정하지 못하는 문제를 말한다. 예를 들어 로봇이 짐을 가지러 방에 들어간다고 할 때 로봇은 '짐’이라는 목적에만 초점을 맞추고 있기 때문에 짐 위에 꽃병이 높여있더라도 전혀 신경 쓰지 않고 짐을 들어 올려서 꽃병을 깨고 말 것이다. 그렇다고 짐 주변을 모두 신경쓰게 되면 로봇이 고려할 범위가 끝도 없이 늘어나게 된다. 이처럼 컴퓨터가 적절한 범위를 제대로 정할 수 없는 문제를 가리켜 '프레임 문제’라고 한다. 제2차 부흥기 전문가 시스템(Expert System)으로 전문가의 지식을 컴퓨터에 집어넣은 뒤, 그 지식에 기초하여 판단을 내리는 방식으로 제2차 부흥기가 시작되었다. 예를 들어 의사가 환자를 진찰할 때에 여러가지 증상을 관찰하고 이를 기반으로 어떠한 치료와 투약을 하면 좋을지 판단한다. 이 때 의사가 사용하는 지식을 컴퓨터에 입력해둠으로써 컴퓨터가 마치 의사처럼 판단을 내리게 한다. 이 때 주된 개념은 '지능이란 곧 지식이다’였다. 이전까지의 연구로 컴퓨터가 스스로 현실 세계에 대해 고려하기는 힘들다는 사실이 판명되었으므로 인간이 가르쳐서 똑똑하게 만들어주자는 생각을 했었고 대화시스템에서도 지식을 갖춤으로써 고도의 대화를 할 수 있다는 것이 확인되었다. 대표적으로 'GUS(genial understander system)'를 들 수 있다. 하지만 말로 설명할 수 있는 지식은 컴퓨터에 입력할 수 있지만 전문가라면 말로 설명하기 힘든 지식도 가지고 있게 되는데 컴퓨터에게는 ‘대체로’, '적당히’와 같은 정량화되지 않은 부분은 입력이 어려웠다. 이러한 문제를 지식 획득 병목(Knowledge acquisition bottleneck)라고 불렀고 이러한 지식을 얻기 위한 비용이 너무 높아지게 되어서 제2차 부흥기도 금방 사그라들게 된다. 제3차 부흥기 2010년 이후부터 딥러닝으로 인해 비약적인 발전을 이루게 되는데 이미지 분야 같은 경우는 인공지능이 인간을 능가하게 되었다. 딥리닝의 특징은 인간이 개입하지 않아도 특징을 자동으로 찾아낸다는 데 있다. 이전 전문가 시스템까지는 인간이 특정 조건과 지식을 입력해주면 컴퓨터가 처리하는 식으로 진행되었으나, 딥러닝은 이런한 과정을 자동으로 처리하게 개발되었다. 이러한 현상을 바탕으로 주된 개념은 '지능이란 곧 학습이다’였다. 딥러닝에서는 대량의 데이터를 기반으로 학습하여 규칙성을 발견함으로써 대상을 분류하게 된다. 예를 들어 Google의 고양이(Using large-scale brain simulations for machine learning and A.I.)를 분류하기 위해 레이블을 달아놓은 학습데이터 25,000장, 테스트데이터 12,500장으로 구성하여 학습을 하고 이를 활용하여 분류를 했다. 딥러닝을 활용한 연구 개발이 매우 활발해지면서 레이블이 달린 혹은 분류되어 있는 대량의 데이터가 필요하게 되었고 데이터를 모으는 일 자체가 큰 비용이 들어가는 아이러니한 현상이 벌어지게 되었다. 평가방법 튜링테스트 튜링테스트는 인공지능이 인간과 같은 반응을 할 수 있는지를 판단하기 위한 테스트로 1950년 '이미테이션 게임’이라는 이름으로 튜닝이 발안하였다. 예를 들어 어떤 사람이 다른 곳에 있는 두 사람과 채팅으로 이야기를 하고 있는데 이야기 대상인 두 사람 중 하나는 인간, 하나는 컴퓨터이다. 그리고 테스터가 둘 중 어느 쪽이 인간이고 어느 쪽이 컴퓨터인지를 판별하지 못하면 그 컴퓨터는 튜링 테스트에 합격하게 된다. 튜링은 발안할 당시에 '5분 동안 이야기를 나눠본 뒤 30%의 사람이 속는다면 그 시스템은 튜링 테스트에 통과했다고 볼 수 있다.'고 합격기준을 제시하였다. '유진(Eugene Goostman)'이라는 13세 우크라이나인 설정을 가진 챗봇은 튜닝테스트를 통과했다고 발표한 적이 있다. 그러나 테스트 시간이 너무 짧고 우크라이나인이라는 설정 때문에 영어 문법이나 이야기하는 내용이 다소 이상해도 넘어가기 쉬웠다는 점에서 튜닝테스트를 완벽히 통과했다고 보기는 어렵다. 또한 튜링테스트를 완벽히 통과했다고 해서 인공진능이 완벽해지는 것이 아니고 ‘유진’ 사례에서 보는 바와 같이 결과 뿐만 아니라 환경, 과정까지 모두 살펴보아야 한다. 중국어 방 튜링테스트에 대한 대표적인 반론으로는 중국어 방(Chinese Room)을 들 수 있다. 이것은 내부 구조와 관계없이 표면적인 행동에만 주목하여 평가하는 '기능주의’에 대한 회의적인 입장에 기반한 사고 실험에서 출발하여 존 설(John Searle)이 발표하였다. 중국어 방의 사고실험을 통해 '튜링 테스트는 대화가 성립하는 것만으로 통과라 보지만, 그것만으로는 정말 인간과 같이 내용을 이해했다고 할 수 없다’고 반론하였고 강한 인공지능(Strong AI, General AI)과 약한 인공지능(Weak AI, Narrow AI)를 말하게 되었다. 강한 인공지능 : 정말 스스로 생각하는 듯한 인공지능 약한 인공지능 : 스스로 생각하지 않고 정해진 절차에 따라 처리를 수행할 뿐인 인공지능 각 분야별 평가방법 분류 정밀도 예를 들어 100장의 이미지가 있고 각각 고양이, 개, 인간 라벨이 있는 경우 각 이미지가 어느 이미지인지를 인공지능에게 판별시킨 뒤 정답률을 산출시킨다. $$ 분류 정밀도 = \\frac{올바르게 분류한 수}{대상 총 수} $$ 오인식률 음성인식의 경우 얼마만큼의 단어를 잘못 인식했는가를 나타내는 비율(Word Error Rate)로 계산한다. 음식인식의 오류에는 대치오류[1], 삭제오류[2], 삽입오류[3]가 있으며 이 오류들의 수를 원래 인식했어야 할 단어의 수로 나누면 오인식률이 된다. $$ 오인식률 = \\frac{오류수의 총합}{인식해야 하는 총수} $$ 주관평가 기계 번역이나 대화 시스템과 같은 분야에서는 정답을 하나로 단정하기 어렵다. 이러한 분야에서는 많은 유저에게 실제로 기술을 사용하게 한 뒤, 설문조사를 통해 평가를 진행하는 방식(주관평가, Subjective Evaluation)을 채택한다. 단, 평가가 주관적으로 이루어지므로 보다 많은 사람에게 평가를 받아서 결과를 평균화시켜야 하며, 이 때문에 매번 많은 사람을 동원하다간 비용이 높아지고 만다. 그래서 대부분 '자동평가척도’를 사용하는 경우가 많다. 자동 평가 측도 기계번역을 예로 들면, 많은 수의 문장을 사람과 시스템에게 각각 번역시킨다. 그 다음에는 사람의 번역과 기계의 번역을 비교해서 번역을 평가하기 위한 평가 척도를 정한다. 예를 들어 사람의 번역에 들어있는 표현이 기계의 번역에도 들어있다면 좋은 번역일 가능성이 높으므로 '사람의 번역에 들어있는 표현의 개수’가 평가 척도가 된다. 그 평가 척도의 타당성을 '상관 계수’를 사용하여 검증한다. 참고로 현재 기계 번역에서 사용되는 평가 척도 중 가장 유명한 것은 'BLUE(Bilingual Evaluation Understudy)'이다. 일단 자동 평가 척도가 결정되고 나면 대역 데이터에 대해 평가가 높아지도록 알고리즘 연구 개발을 진행한다. 그러면 평가에 대한 사람의 개입이 줄어들게 되어 개발 비용이 현저히 낮아질 수 있다. 기초 난수발생 신경망을 쉽게 정의해보면 많은 숫자로 구성된 행렬이라고 할 수 있다. 이 행렬에 어떤 입력을 넣으면 출력을 얻게 되는데 행렬을 구성하는 숫자는 처음에는 랜덤한 값을 지정해줄 수 밖에 없다. 처음에는 랜덤한 값을 지정해줄 수 밖에 없다. 처음에 신경망의 초기값을 지정해주는 것을 초기화(Initialization)라고 하며 Xavier초기화와 He초기화가 많이 쓰인다. 이 방법들은 랜덤하지만 어느정도 규칙성이 있는 범위 내에서 난수를 지정한다. tensorflow에서는 tf.random.uniform 함수를 불러오면 균일 분포(uniform distribution)의 난수를 얻을 수 있다. 균일 분포는 최솟값과 최댓값 사이의 모든 수가 나올 확률이 동일한 분포에서 수를 뽑는다는 뜻이다. 1Tensorflow Code tf.random.normal 함수를 불러오면 정규 분포(normal distribution)의 난수를 얻을 수 있다. 정규 분포는 가운데가 높고 양극단으로 갈수록 낮아져서 종 모양을 그리는 분포를 말한다. title1234import tensorflow as tfrand = tf.random.uniform([1],0,1)print(rand) 배열곱 리스트에 정수를 곱하면 양수일 경우 숫자만큼 리스트의 원소를 반복하고, 0 이하일 경우 빈 리스트를 반환하고 실수를 곱하면 에러를 발생한다. 1234import tensorflow as tfrand = tf.random.normal([4],0,1)print(rand) numpy를 사용해 array에 숫자를 곱하게 되면 각 원소에 대해 자동으로 숫자를 곱하는 연산이 이루어지는데, 이를 각 원소에 대한 연산(element-wise operation)이라고 한다. 12345import numpy as npprint(np.array([1,2,3])*2)print(np.array([1,2,3])*0)print(np.array([1,2,3])*-1)print(np.array([1,2,3])*0.01) 뉴럽(퍼셉트론, 신경세포) 신경망은 뉴런이 여러 개 모여 레이어(층)를 구성한 후 이 레이어가 다시 모여 구성한 형태이다. 뉴런은 입력, 가중치, 활성화함수, 출력으로 구성된다. $$ Y=f(X \\times w)\\ \\ \\scriptsize 입력치 X,가중치 w, 출력 Y, 활성화함수 f $$ 뉴런에서 학습할 때 변하는 가중치는 처음에는 초기화를 통해 랜덤한 값을 넣고, 학습 과정에서 점차 일정한 값으로 수렴한다. 가중치 조정을 통해 원하는 출력에 가깝게 조정하여 모델을 향상시키게 된다. 결국 간단하게 보면 \\(w\\)가 뉴런이라 생각할 수 있다. 활성화 함수로는 시그모이드(sigmoid), ReLU(Rectified Linear Unit) 등을 많이 사용하게 된다. 신경망 초창기에는 시그모이드가 주로 쓰였지만 은닉층을 많이 사용하는 딥러닝에서 오류를 역전파(Backpropagate)할 때 시그모이드 함수가 값을 점점 작아지게 하는 문제를 2010년 논문[4]토론토 대학교의 비노드 네어와 제프리 힌튼 교수가 지적하면서 ReLU를 대안으로 제시하였다. 시그모이드 함수는 출력값을 0~1 사이로만 제한되어 있지만 ReLU는 양수를 그대로 반환하기 때문에 값의 왜곡이 적어진다. 예를 들어 시그모이드 함수를 사용하여 1을 입력할 경우 기대출력이 0이 되는 뉴런을 만들어보면 아래와 같다. 1234567891011121314151617import mathimport tensorflow as tfdef sigmoid(x): return 1 / (1 + math.exp(-x))x = 1y = 0w = tf.random.normal([1],0,1)for i in range(1000): output = sigmoid(x * w) error = y - output w = w + x * 0.1 * error if i%100 == 99: print(i, error, output) 이 코드에서는 경사하강법(Gradient Descent)를 사용했는데 \\(w\\)에 입력\\(x\\), 학습률\\(\\alpha\\), 에러\\(error\\)의 곱을 합한 값으로 학습률이 너무 큰 경우 학습이 빠르지만 적정한 수치를 벗어날 우려가 있고, 너무 작은 값은 학습 속도가 너무 느려질 수 있다. 1234567891099 -0.08803679043528755 0.08803679043528755199 -0.048206592326328714 0.048206592326328714299 -0.032931402098842766 0.032931402098842766399 -0.024941436740358217 0.024941436740358217499 -0.020047549096087545 0.020047549096087545599 -0.01674840932694568 0.01674840932694568699 -0.014376145500721372 0.014376145500721372799 -0.012589411771020347 0.012589411771020347899 -0.011195832981499537 0.011195832981499537999 -0.010078814583572272 0.010078814583572272 위 결과에 보면 error는 0에 점점 가까워지고 output도 기대출력인 0에 가까워지는 것을 확인할 수 있다. 그런데 입력값과 기대출력을 바꾸면 동일한 결과가 나올까? 간단히 수식에서 생각해보면 (x) 가 0이기 때문에 값이 변하지 않게 된다. 이런 경우를 방지하기 위해 편향(bias)를 추가하게 되며 아래와 같이 사용하게 된다. $$ Y=f(X \\times w + 1 \\times b) \\ \\ \\scriptsize 입력치 X,가중치 w, 출력 Y, 편향 b, 활성화함수 f $$ 1234567891011121314151617181920import mathimport tensorflow as tfdef sigmoid(x): return 1 / (1 + math.exp(-x))x = 0y = 1alpha = 0.1w = tf.random.normal([1],0,1)b = tf.random.normal([1],0,1)for i in range(1000): output = sigmoid(x * w + 1* b) error = y - output w = w + x * alpha * error b = b + 1 * alpha * error if i%100 == 99: print(i, error, output) 1234567891099 0.07355049116562629 0.9264495088343737199 0.04336122942384402 0.956638770576156299 0.03056554939033551 0.9694344506096645399 0.0235506250070594 0.9764493749929406499 0.019135113381853364 0.9808648866181466599 0.016104868965294172 0.9838951310347058699 0.013898372317313057 0.9861016276826869799 0.012220898985253581 0.9877791010147464899 0.010903078202945005 0.989096921797055999 0.00984069902829432 0.9901593009717057 신경망 네트워크 AND AND연산은 입력이 모두 참 값일 때 참이 되고, 그 밖의 경우에는 모두 거짓이 된다. 값을 두 개로 제한하게 되면 아래와 같은 표를 구성할 수 있다. 입력1 입력2 결과 참 참 참 참 거짓 거짓 거짓 참 거짓 거짓 거짓 거짓 식으로 나타내면 아래와 같다. $$ Y=f(X_1 \\times w_1 + X_2 \\times w_2 + 1 \\times b) $$ 다음 코드는 참을 1, 거짓을 0의 정수값으로 설정하고 코드를 작성했다. 12345678910111213141516171819202122232425import mathimport tensorflow as tfimport numpy as npdef sigmoid(x): return 1 / (1 + math.exp(-x))x = np.array([[1,1],[1,0],[0,1],[0,0]])y = np.array([[1],[0],[0],[0]])w = tf.random.normal([2],0,1)b = tf.random.normal([1],0,1)b_x = 1alpha = 0.1for i in range(2000): error_sum = 0 for j in range(4): output = sigmoid(np.sum(x[j]*w)+b_x*b) error = y[j][0] - output w = w + x[j] * alpha * error b = b + b_x * alpha * error error_sum += error if i % 200 == 199: print (i, error_sum) 12345678910199 -0.11417635227874308399 -0.06704566564399024599 -0.047357577895359125799 -0.036500511856403565999 -0.029636905412076681199 -0.0249170597496768121399 -0.0214763375558961431599 -0.0188622308823781331799 -0.0168069230602205561999 -0.015152206075212815 기타 Sigmoid ReLU Gradient Descent 참고자료 하가사나카 류이치로. 아무것도 모르고 시작하는 인공지능 첫걸음. 한빛미디어, 2018. 백성민. 시작하세요! 텐서플로우 2.0 프로그래밍. 위키북스, 2020 원준. 딥러닝을 이용한 자연어 처리 입문. https://wikidocs.net/book/2155 다른 단어를 잘못 들은 경우 ↩︎ 못 듣고 놓친 경우 ↩︎ 없는 단어를 들었다고 착각한 경우 ↩︎ Vinod Nair and Geoffrey E. Hinton, Rectified Linear Units Improve Restricted Boltzmann Machines , 2010 ↩︎","link":"/2020/04/20/Artificial%20Intelligence/"}],"tags":[{"name":"ai","slug":"ai","link":"/tags/ai/"},{"name":"인공지능","slug":"인공지능","link":"/tags/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5/"}],"categories":[{"name":"technology","slug":"technology","link":"/categories/technology/"}]}